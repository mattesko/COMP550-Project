{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qkt0rqbRxG7"
   },
   "source": [
    "** Read stuff from your own gdrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "n49pRSfNKtbA",
    "outputId": "89e08372-79c7-48c7-e96a-f065e8da5274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: =1.2.0: No such file or directory\n",
      "Collecting torchtext==0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.12.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.3.1+cu100)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.17.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (4.28.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
      "Installing collected packages: torchtext\n",
      "  Found existing installation: torchtext 0.3.1\n",
      "    Uninstalling torchtext-0.3.1:\n",
      "      Successfully uninstalled torchtext-0.3.1\n",
      "Successfully installed torchtext-0.4.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torchtext"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch<=1.2.0\n",
    "!pip install torchtext==0.4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "D6vcbT3cK0g8",
    "outputId": "d5630288-14ff-4e63-90e7-d4f229eb03e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.7)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.4.2)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMGLSlF6R9YW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "jmjGYZrsSMnz",
    "outputId": "2bbafedb-dfc3-4bee-fea6-61d26cf46dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the corpus data\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uanjk8B-ldR_"
   },
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "1M0RQ8BR6k2h",
    "outputId": "1c12da2a-3fa5-43fa-a09f-31c0dd729a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "['a', 'about', 'abov', 'across', 'aft', 'afterward', 'again', 'against', 'al', 'almost']\n"
     ]
    }
   ],
   "source": [
    "MY_HOME = \"My Drive/nlp\"\n",
    "stop_words = [\n",
    "        \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\",\n",
    "        \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "        \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\", \"at\", \"back\", \"be\",\n",
    "        \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "        \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\", \"call\", \"can\", \"co\",\n",
    "        \"con\", \"could\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\",\n",
    "        \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "        \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\",\n",
    "        \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\",\n",
    "        \"has\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\",\n",
    "        \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\",\n",
    "        \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\",\n",
    "        \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\",\n",
    "        \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"nevertheless\", \"next\", \"nine\", \"nobody\", \"now\", \"nowhere\",\n",
    "        \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\",\n",
    "        \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\",\n",
    "        \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\",\n",
    "        \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\",\n",
    "        \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "        \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\",\n",
    "        \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\",\n",
    "        \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\",\n",
    "        \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\",\n",
    "        \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\",\n",
    "        \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\"\n",
    "        ]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "def _tokenize_stem_lem_join(text):\n",
    "    \"\"\"Stem and lemmatize text by tokenizing and joining back together\"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = _stem_words(words)\n",
    "    words = _lemmatize_verbs(words)\n",
    "    return ' '.join(words)\n",
    "    \n",
    "\n",
    "def _stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "\n",
    "def _lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "stop_words_preproc = []\n",
    "for word in stop_words:\n",
    "    temp = _tokenize_stem_lem_join(word)\n",
    "    stop_words_preproc.append(temp)\n",
    "\n",
    "print(stop_words_preproc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gvC0_NKjZyW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def split_train_test(df, train=0.60):\n",
    "    train_size = round(len(df) * train)\n",
    "    train_indices = random.sample(population=df.index.tolist(), k=train_size)\n",
    "    train_df = df.loc[train_indices]\n",
    "    test_df = df.loc[set(df.index) - set(train_df.index)] #get rest of index\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bghsqE5i3188",
    "outputId": "02298ff8-99fe-4089-877b-85302704860e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def one_hot(a, num_classes):\n",
    "  a = np.array([a])\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
    "\n",
    "print(one_hot([[1], [0]], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q-lOOjJ5kH0"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "\n",
    "def to_tdidf(_lim_unigram=500):\n",
    "    \"\"\"\n",
    "    prepare utils for torch dataset\n",
    "    \"\"\"\n",
    "    print(\"======> create util vectorizers and some mapping for torch dataset\")\n",
    "    data = pd.read_pickle(os.path.join(\"drive/My Drive/nlp\", \"preprocessed_claim_body.pkl\"))\n",
    "    id_ref = {}\n",
    "\n",
    "    \n",
    "    print(data.head())\n",
    "    lim_unigram = _lim_unigram\n",
    "    # no more ram, limit this\n",
    "    # TODO: change to training set, not a simple slicing\n",
    "    # Create reference dictionary\n",
    "    for i, elem in enumerate(data['claim'] + data['body']):\n",
    "        id_ref[elem] = i\n",
    "    bow_vectorizer = CountVectorizer(max_features=lim_unigram, stop_words=stop_words_preproc)\\\n",
    "                  .fit(data['claim'][0:90] + data['body'][0:90])\n",
    "    bow = bow_vectorizer.transform(data['claim'][0:90] + data['body'][0:90])\n",
    "    tfreq_vectorizer = TfidfTransformer(use_idf=False).fit(bow)\n",
    "    tfreq = tfreq_vectorizer.transform(bow).toarray()\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=lim_unigram, stop_words=stop_words_preproc).\\\n",
    "        fit(data['claim'] + data['body'])  # Train and test sets\n",
    "  \n",
    "    return id_ref, bow, tfreq, tfidf_vectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whTE8QkuTWSO"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(64+64+1, 100)\n",
    "        self.fc2 = nn.Linear(100, 3)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFvYxuQDVi72"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class ClaimBodyDataset(Dataset):\n",
    "    \"\"\"claim body dataset for training\"\"\"\n",
    "    # TODO: check using loading the dataframe directly\n",
    "    def __init__(self, df, _lim_unigram=500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df is the dataframe, sliced either train or test, still has the two columns!\n",
    "            claim: 5000 by 1\n",
    "            body: 5000 by 1\n",
    "            cosine_similarity: 1 by 1\n",
    "        \"\"\"\n",
    "        self.df = df #pd.read_pickle(df)\n",
    "        self.lim_unigram = _lim_unigram\n",
    "        self.bow_vectorizer_claim = CountVectorizer(max_features=self.lim_unigram, stop_words=stop_words_preproc)\n",
    "        self.bow_vectorizer_body = CountVectorizer(max_features=self.lim_unigram, stop_words=stop_words_preproc)\n",
    "\n",
    "        self.bow_claim = self.bow_vectorizer_claim.fit_transform(self.df['claim'])\n",
    "        self.bow_body = self.bow_vectorizer_body.fit_transform(self.df['body'])\n",
    "        \n",
    "\n",
    "        self.tfreq_vectorizer_claim = TfidfTransformer(use_idf=False).fit(self.bow_claim)\n",
    "        self.tfreq_vectorizer_body = TfidfTransformer(use_idf=False).fit(self.bow_body)\n",
    "\n",
    "\n",
    "        self.tfreq_claim = self.tfreq_vectorizer_claim.transform(self.bow_claim).toarray()\n",
    "        self.tfreq_body = self.tfreq_vectorizer_body.transform(self.bow_body).toarray()\n",
    "\n",
    "        pca = PCA(n_components=64)\n",
    "        self.tfreq_claim_reduced = pca.fit_transform(self.tfreq_claim)\n",
    "        self.tfreq_body_reduced = pca.fit_transform(self.tfreq_body)\n",
    "\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(max_features=self.lim_unigram, stop_words=stop_words_preproc).\\\n",
    "        fit(self.df['claim'] + self.df['body'])  # Train and test sets\n",
    "\n",
    "        self.tfidf_claim = self.tfidf_vectorizer.transform(self.df['claim'])\n",
    "        self.tfidf_body = self.tfidf_vectorizer.transform(self.df['body'])\n",
    "\n",
    "        self.cosine_similarity = cosine_similarity\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "\n",
    "        claim_tfreq= self.tfreq_claim_reduced[idx]\n",
    "        body_tfreqf = self.tfreq_body_reduced[idx]\n",
    "\n",
    "\n",
    "\n",
    "        claim_tfidf = self.tfidf_claim[idx]\n",
    "        body_tfidf = self.tfidf_body[idx]\n",
    "\n",
    "        cos_tfidf = cosine_similarity(claim_tfidf, body_tfidf)[0].reshape(1, -1)\n",
    "        feat_vec = np.squeeze(np.c_[claim_tfreq.reshape(1, -1), body_tfreqf.reshape(1, -1), cos_tfidf])\n",
    "        label = self.df['label'].iloc[idx]\n",
    "\n",
    "        feat_vec = torch.from_numpy(feat_vec)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return feat_vec, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5ZEclSAFZyba",
    "outputId": "5b88dfd2-6da1-4471-e01a-115cad5a183d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([-0.0804, -0.0877, -0.0178, -0.0800, -0.0005, -0.0320, -0.0423, -0.0042,\n",
      "         0.0027, -0.0491,  0.0192, -0.0312,  0.0167, -0.0050, -0.0227, -0.0055,\n",
      "         0.0116, -0.0010, -0.0079,  0.0006, -0.0099, -0.0077, -0.0331, -0.0084,\n",
      "         0.0169,  0.0132,  0.0002, -0.0122, -0.0062, -0.0024, -0.0015, -0.0147,\n",
      "        -0.0022, -0.0045, -0.0350,  0.0017,  0.0374,  0.0209, -0.0210,  0.0010,\n",
      "         0.0005, -0.0101, -0.0400, -0.0091, -0.0340, -0.0031, -0.0514, -0.0746,\n",
      "         0.0285, -0.0740,  0.0435,  0.0581, -0.0148, -0.0353, -0.0571,  0.0693,\n",
      "        -0.0075, -0.0712, -0.0754,  0.0043,  0.0279,  0.0080, -0.0334, -0.0249,\n",
      "        -0.1533,  0.1215, -0.1111, -0.1639,  0.0329, -0.0033, -0.0062,  0.0588,\n",
      "        -0.0106,  0.0087,  0.0029,  0.0239,  0.0204, -0.0613,  0.0224, -0.0361,\n",
      "         0.0363,  0.0221, -0.0595, -0.0368, -0.0382, -0.0169, -0.0846, -0.0077,\n",
      "         0.0245, -0.0183, -0.0388,  0.0948, -0.0290, -0.0160,  0.0521,  0.1092,\n",
      "        -0.0381,  0.0543,  0.0641, -0.0449,  0.0988, -0.0040, -0.0215, -0.0225,\n",
      "         0.0290, -0.0248,  0.0904, -0.0491,  0.0731, -0.0239,  0.0530, -0.0184,\n",
      "        -0.0280,  0.0243,  0.0153,  0.0308,  0.0085, -0.0533, -0.0836,  0.0149,\n",
      "         0.0038, -0.0635, -0.0955, -0.0015,  0.0111,  0.0500,  0.0064,  0.0237,\n",
      "         0.0349], dtype=torch.float64), tensor(0)) torch.Size([129])\n",
      "1 (tensor([-0.0767, -0.0815, -0.0272, -0.0581, -0.0319,  0.0113, -0.0410, -0.0071,\n",
      "        -0.0103, -0.0565,  0.0141, -0.0347, -0.0031, -0.0064, -0.0176,  0.0123,\n",
      "         0.0281, -0.0535,  0.0215,  0.0425, -0.0216, -0.0537,  0.0068, -0.0036,\n",
      "         0.0037,  0.0585, -0.0434,  0.0163, -0.0043,  0.0086,  0.0556, -0.0370,\n",
      "         0.0038, -0.0146, -0.0719, -0.0171,  0.1119,  0.0298,  0.0478,  0.0086,\n",
      "        -0.0860, -0.1270, -0.1754,  0.3171,  0.0982,  0.0701,  0.0844,  0.0507,\n",
      "        -0.0088,  0.0579, -0.0499, -0.0715, -0.0073,  0.0184,  0.0915,  0.0309,\n",
      "         0.1033,  0.0997,  0.0784, -0.0489,  0.0283,  0.1638, -0.0185,  0.0214,\n",
      "        -0.2617,  0.0714, -0.2016, -0.2708,  0.1260, -0.0998,  0.0552,  0.2344,\n",
      "        -0.0826, -0.1036, -0.0466,  0.0326, -0.0204,  0.0330,  0.0015, -0.0286,\n",
      "         0.1223, -0.0015, -0.0139,  0.0748, -0.0300,  0.0113, -0.0160, -0.0045,\n",
      "         0.0900,  0.0615,  0.0158, -0.0437,  0.0321, -0.0305, -0.0668, -0.0811,\n",
      "        -0.0930, -0.0436, -0.0241,  0.0403, -0.1201, -0.0016,  0.0016, -0.0925,\n",
      "        -0.0759, -0.0097,  0.0147,  0.0772, -0.0333,  0.0590,  0.0023, -0.0007,\n",
      "        -0.0589,  0.0185, -0.0539, -0.0162, -0.0111,  0.0070,  0.0138, -0.0499,\n",
      "         0.0034,  0.0153, -0.0238, -0.0061, -0.0006, -0.0121, -0.0225, -0.0743,\n",
      "         0.3947], dtype=torch.float64), tensor(0)) torch.Size([129])\n",
      "2 (tensor([-1.2777e-01, -8.1991e-02,  4.8138e-02,  2.3860e-01,  1.3793e-01,\n",
      "        -1.4319e-01,  3.5975e-01,  8.2591e-02, -9.0590e-02,  2.1545e-01,\n",
      "        -1.7141e-01,  3.1432e-01, -1.3534e-01,  1.4750e-01, -2.2387e-01,\n",
      "        -1.6866e-01,  2.8127e-02,  4.5329e-02, -1.6741e-01,  7.1140e-02,\n",
      "         5.0197e-02, -8.7261e-02,  1.3410e-01, -6.3432e-02,  1.7824e-02,\n",
      "        -6.6716e-03, -3.3015e-03,  3.7813e-02,  4.8741e-04, -3.3380e-02,\n",
      "        -5.6580e-02,  5.0051e-03, -2.2328e-03, -2.9715e-02, -2.5184e-02,\n",
      "         1.1108e-03,  2.4801e-02,  1.5953e-02,  1.9202e-02,  3.6039e-02,\n",
      "         4.1576e-02,  6.4692e-02,  1.8213e-02,  2.3337e-02, -1.9145e-02,\n",
      "         3.0644e-02, -7.6384e-02,  3.6648e-03,  8.3584e-02,  1.4321e-01,\n",
      "        -3.1499e-02,  3.0943e-02,  1.1286e-01, -2.1379e-02,  1.1154e-01,\n",
      "        -5.3340e-02,  4.3418e-02,  6.3381e-02,  1.2403e-02, -1.2202e-01,\n",
      "         1.7051e-01, -5.7464e-02, -9.4597e-02,  3.8115e-03, -4.0426e-02,\n",
      "         3.8870e-01, -2.8984e-02,  9.5462e-02, -1.8636e-02,  7.5362e-02,\n",
      "         2.2923e-01,  7.4515e-02,  1.0069e-03, -3.6490e-02, -1.1057e-02,\n",
      "         4.6850e-02, -1.1995e-02, -3.8412e-02,  1.3885e-04, -7.3786e-03,\n",
      "         5.8623e-02,  9.9057e-02, -4.2135e-02, -4.8225e-02,  9.1813e-02,\n",
      "        -6.1314e-02,  8.5567e-02, -1.8132e-01,  1.5509e-01,  4.8308e-02,\n",
      "         1.6649e-01,  6.7552e-02,  4.2453e-02,  7.6274e-02,  4.5991e-02,\n",
      "        -1.4716e-02,  2.1682e-01, -8.4339e-03, -1.8871e-01,  8.8274e-02,\n",
      "         9.6739e-03, -3.2096e-02,  1.5935e-01,  2.4273e-01,  3.1838e-01,\n",
      "        -1.5010e-01,  3.5892e-02,  3.0271e-01,  2.3065e-01,  2.3886e-01,\n",
      "        -6.6074e-02,  1.5300e-01,  1.4992e-01,  9.3708e-02, -6.7015e-02,\n",
      "        -1.7916e-02,  2.2682e-01, -2.5749e-02, -2.9831e-02,  4.8368e-02,\n",
      "         9.0369e-02, -3.7078e-02,  9.3009e-03, -1.1766e-02, -1.0592e-01,\n",
      "        -4.7905e-02, -5.8379e-02,  2.5339e-03,  1.3322e-01],\n",
      "       dtype=torch.float64), tensor(1)) torch.Size([129])\n",
      "3 (tensor([-8.9377e-02, -9.3941e-02, -2.7002e-02, -8.3691e-02, -2.6999e-02,\n",
      "        -1.3649e-02, -6.1098e-02,  2.1503e-03,  1.1171e-02, -9.3841e-02,\n",
      "         5.1489e-02, -1.4925e-02, -2.0340e-02,  1.3883e-02, -1.5319e-02,\n",
      "        -8.9300e-03,  5.5758e-02, -1.9314e-02,  1.4577e-02, -5.7426e-02,\n",
      "        -7.0073e-02,  1.1582e-02,  8.1663e-02, -5.1243e-02, -1.4773e-02,\n",
      "         1.4408e-01,  3.0436e-01,  3.2428e-01, -1.1035e-01,  6.2341e-02,\n",
      "         1.2561e-01,  7.6786e-03,  1.8646e-02,  1.0479e-01, -5.3901e-02,\n",
      "         7.9791e-03, -3.3509e-02, -2.3276e-02,  4.1565e-02,  1.1777e-01,\n",
      "         2.9009e-02,  4.6385e-02,  9.2720e-03, -5.1517e-02, -9.0830e-02,\n",
      "         8.5828e-04, -4.3452e-02, -8.4258e-03, -8.2024e-02, -4.1794e-02,\n",
      "         9.0292e-02,  5.9317e-02, -1.9791e-01, -1.0685e-01,  5.6400e-02,\n",
      "         2.7992e-03,  4.0413e-02,  4.7023e-02,  7.9475e-02, -1.4499e-02,\n",
      "         5.7897e-02, -3.8904e-02,  3.1253e-02,  6.3469e-02, -1.3555e-01,\n",
      "        -5.3856e-02, -9.2391e-02, -2.1646e-01, -7.2448e-02,  7.4432e-02,\n",
      "        -5.2361e-02, -3.3805e-02, -1.6733e-02, -8.6288e-02, -9.8427e-02,\n",
      "        -6.3260e-02,  6.1531e-02, -5.4483e-02,  1.4803e-01,  9.0745e-02,\n",
      "        -2.0462e-01, -9.1379e-02,  4.2676e-02, -1.8172e-02,  2.0491e-01,\n",
      "        -1.1739e-01,  6.3848e-02, -8.5985e-02, -2.6271e-02,  8.6855e-02,\n",
      "        -5.6230e-02,  8.3224e-02, -5.6685e-02, -3.8640e-02, -1.1553e-01,\n",
      "        -3.7328e-02, -5.7644e-02,  9.3943e-02, -2.1348e-02,  1.5665e-02,\n",
      "        -9.1951e-02,  1.8116e-02,  8.2230e-02,  2.0778e-02, -2.4614e-02,\n",
      "         9.9229e-03, -4.5591e-02, -2.8384e-02, -3.1123e-02,  8.6577e-02,\n",
      "         2.5252e-02, -6.1560e-02, -3.7577e-02,  5.1437e-03,  1.9090e-02,\n",
      "         1.0391e-05,  3.1859e-02, -1.7097e-02, -1.3503e-02,  7.3746e-02,\n",
      "         1.9272e-02, -4.9529e-02, -6.8374e-02, -6.7394e-03,  2.8277e-02,\n",
      "        -3.9422e-02,  3.2065e-02,  6.1196e-02,  4.6699e-01],\n",
      "       dtype=torch.float64), tensor(0)) torch.Size([129])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(os.path.join(\"drive/My Drive/nlp\", \"preprocessed_claim_body_full.pkl\"))\n",
    "train_df, test_df = split_train_test(data, train=0.8)\n",
    "\n",
    "train_dataset = ClaimBodyDataset(train_df)\n",
    "test_dataset = ClaimBodyDataset(test_df)\n",
    "# note: mostly zero!\n",
    "for i in range(4):\n",
    "    sample = train_dataset[i]\n",
    "    print(i, sample, sample[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "uZOZ_7IjCJJE",
    "outputId": "a491a257-5e8d-4468-9d32-ed22f2a07b7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'false'), Text(0, 0, 'partially true'), Text(0, 0, 'true')]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZoWcLMzMrND/B1AzX366UawLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = data['label'].hist(bins=3, grid=False)\n",
    "hist.set_xticks([0 ,1 ,2])\n",
    "hist.set_xlabel('Labels')\n",
    "hist.set_ylabel('Number of instances')\n",
    "\n",
    "hist.set_xticklabels(['false', 'partially true', 'true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_Bx7uazkmBh-",
    "outputId": "c9f0b2ea-af6a-4d0c-dc88-4ebaf442eae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444\n",
      "3111\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df.index))\n",
    "print(len(test_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M5ITnVCIMnHr",
    "outputId": "0712d693-fba2-471d-ae5b-6598c6ecd4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 1])\n"
     ]
    }
   ],
   "source": [
    "# we print some examples to see how sparse this is\n",
    "print(torch.nonzero(sample[0]).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6LzT3-RaoKH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "5tR_GL47T_yq",
    "outputId": "567f4a5a-2d43-4c89-96c5-6ab492a29b13"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b7f803f5c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.Tensor([0.1, 0.1, 0.8]).to(device))\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vR0OP1dwmLg9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=.2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        y_onehot = one_hot(target.cpu().numpy(), 3) # 3 classes\n",
    "        y_onehot = torch.FloatTensor(y_onehot).to(device).long()\n",
    "        target = y_onehot\n",
    "\n",
    "        # target = target.view(-1,1)\n",
    "        # print(\"taret\", target.size())\n",
    "        logpt = input #F.log_softmax(input)\n",
    "        # print(\"logpt\", logpt.size())\n",
    "\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7vDaMuTXOgu"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    batch_size = 8\n",
    "    nb_classes = 3\n",
    "    smooth = 1.\n",
    "\n",
    "    y_onehot = one_hot(target.cpu().numpy(), 3) # 3 classes\n",
    "    y_onehot = torch.FloatTensor(y_onehot).to(device)\n",
    "\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = y_onehot.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    cardinality = iflat.sum() + tflat.sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (cardinality + smooth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ghvx_vPimprQ"
   },
   "outputs": [],
   "source": [
    "def dice_with_logits(input: torch.Tensor, target: torch.Tensor, dim=(-2, -1), reduction='mean', eps=1e-6):\n",
    "    # input = input.sigmoid()\n",
    "    y_onehot = one_hot(target.cpu().numpy(), 3) # 3 classes\n",
    "    y_onehot = torch.FloatTensor(y_onehot).to(device)\n",
    "\n",
    "    target = y_onehot\n",
    "    numerator = 2 * (input * target).sum(dim)\n",
    "    denominator = input.pow(2).sum(dim) + target.pow(2).sum(dim)\n",
    "    dice_losses = -numerator/denominator.clamp(eps)\n",
    "    if reduction == 'sum':\n",
    "        loss = dice_losses.sum()\n",
    "    elif reduction == 'mean':\n",
    "        loss = dice_losses.mean()\n",
    "    elif reduction == 'none':\n",
    "        loss = dice_losses\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug12HAAUVTLm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_mlp(trainloader, criterion, optimizer, mlp, device):\n",
    "    \n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        mlp.train()\n",
    "        total_tr, correct_tr = 0, 0\n",
    "        total_val, correct_val = 0, 0\n",
    "        running_loss = 0.0\n",
    "        mean_train_loss = 0.0\n",
    "        mean_valid_loss = 0.0\n",
    "        mean_train_acc = 0.0\n",
    "        mean_valid_acc = 0.0\n",
    "\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = torch.squeeze(labels)\n",
    "            # labels = labels.reshape(1, -1)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            \n",
    "            outputs = mlp(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"loss\", loss.item())\n",
    "            # print statistics\n",
    "\n",
    "            _, predicted_tr = torch.max(outputs.data, 1)\n",
    "            correct_tr += (predicted_tr == labels).sum().item()\n",
    "            incorrect_tr = (predicted_tr != labels).cpu().detach().numpy()\n",
    "            running_loss += loss.item()\n",
    "            mean_train_loss += loss\n",
    "            total_tr += labels.size(0)\n",
    "            acc_tr = correct_tr / total_tr\n",
    "            mean_train_acc += acc_tr\n",
    "            # if i % 500 == 99:    # print every 500 mini-batches\n",
    "            #     print('[%d, %5d] loss: %.3f' %\n",
    "            #           (epoch + 1, i + 1, loss.item()))\n",
    "            #     running_loss = 0.0\n",
    "        mean_train_loss /= i + 1\n",
    "        mean_train_acc /= i + 1\n",
    "\n",
    "\n",
    "        # run eval\n",
    "        mlp.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            X = inputs.to(device)\n",
    "            Y = torch.LongTensor(labels)\n",
    "            labels = labels.to(device)\n",
    "            Y = Y.T\n",
    "            Y = Y.to(device)\n",
    "            valid_outputs = mlp(X.float())\n",
    "            _, predicted = torch.max(valid_outputs.data, 1)\n",
    "            valid_loss = criterion(valid_outputs, Y)\n",
    "            mean_valid_loss += valid_loss\n",
    "    \n",
    "            total_val += labels.size(0)\n",
    "            _, predicted_val = torch.max(valid_outputs.data, 1)\n",
    "            correct_val += (predicted_val == labels).sum().item()\n",
    "            valid_acc = correct_val/total_val\n",
    "            mean_valid_acc += valid_acc\n",
    "        mean_valid_loss /= i+1\n",
    "        mean_valid_acc /= i+1\n",
    "\n",
    "        # record the results\n",
    "        train_losses.append(mean_train_loss.item())\n",
    "        train_accuracies.append(mean_train_acc)\n",
    "        valid_losses.append(mean_valid_loss.item())\n",
    "        valid_accuracies.append(mean_valid_acc)\n",
    "        print('\\nEpoch {} train_loss: {}, train_acc: {}, valid_loss: {}, valid_acc: {}'.format(epoch,\n",
    "        mean_train_loss.item(), mean_train_acc * 100, mean_valid_loss.item(), mean_valid_acc * 100))\n",
    "  \n",
    "    print('Finished Training')\n",
    "    return train_losses, train_accuracies, valid_losses, valid_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxrppKq7jQ1q"
   },
   "outputs": [],
   "source": [
    "def accuracy(model, data_x, data_y, device):\n",
    "    model = model.eval() \n",
    "\n",
    "    X = data_x\n",
    "    Y = torch.LongTensor(data_y)\n",
    "    Y = Y.T\n",
    "    output = model(X.float())\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    # arg_maxs is tensor of indices [0, 1, 0, 2, 1, 1 . . ]\n",
    "    num_correct = torch.sum(Y==predicted)\n",
    "    acc = (num_correct * 100.0 / len(data_y))\n",
    "    return acc.item()  # percentage format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnnoxT-4pjSN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "def create_train_test(dataset):\n",
    "    validation_split = .2\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 42\n",
    "    batch_size = 8\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    \n",
    "    # Creating PT data samplers and loaders:\n",
    "    # train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    # train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                          #  sampler=train_sampler, drop_last=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler, drop_last=True)\n",
    "    return validation_loader\n",
    "    # return train_loader, validation_loader\n",
    "\n",
    "def rebal_create_train_test(dataset, df):\n",
    "\n",
    "    class_sample_count = np.array([len(np.where(df['label']==t)[0]) for t in df['label'].unique()])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in df['label']])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    print(\"samples_weight\", samples_weight.size())\n",
    "    batch_size = 8\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=sampler, drop_last=True)\n",
    "    return loader\n",
    "\n",
    "def create_val_test(dataset, df):\n",
    "    batch_size = 8\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                            drop_last=True)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRvXkk0nvupi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "def valid_acc_report(val_loader, device, model):\n",
    "    \"\"\"\n",
    "    A detailed validation set report, from SKlearn's classification report\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    # target_names = ['false', 'partially true', 'true']\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        model = model.eval() \n",
    "\n",
    "        X = inputs.to(device)\n",
    "        Y = torch.LongTensor(labels)\n",
    "        Y = Y.T\n",
    "        Y = Y.to(device)\n",
    "        output = model(X.float())\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        y_pred.append(predicted.cpu().numpy())\n",
    "        y_true.append(Y.cpu().numpy())\n",
    "    \n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    print(classification_report(y_true, y_pred)) #, target_names=target_names))\n",
    "    print(f1_score(y_true, y_pred, average='weighted'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "frsHZGNEo52R",
    "outputId": "8bb21a77-7db0-4c13-d6a8-25d0719e6abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_weight torch.Size([12444])\n"
     ]
    }
   ],
   "source": [
    "train_loader = rebal_create_train_test(train_dataset, train_df)\n",
    "valid_loader = create_val_test(test_dataset, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5KvdufIco5cR",
    "outputId": "6647e7d7-5c89-457a-e66d-18976bd56f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 train_loss: 1.064582109451294, train_acc: 39.6372076733075, valid_loss: 1.1658573150634766, valid_acc: 32.9375924113321\n",
      "\n",
      "Epoch 1 train_loss: 1.0291755199432373, train_acc: 50.81008337764508, valid_loss: 1.1529911756515503, valid_acc: 35.55831326988807\n",
      "\n",
      "Epoch 2 train_loss: 1.007463812828064, train_acc: 53.44424621927991, valid_loss: 1.1754753589630127, valid_acc: 36.57297418786117\n",
      "\n",
      "Epoch 3 train_loss: 0.9901549220085144, train_acc: 55.45369062682217, valid_loss: 1.170036792755127, valid_acc: 37.66019233008679\n",
      "\n",
      "Epoch 4 train_loss: 0.9612773656845093, train_acc: 57.6184562937836, valid_loss: 1.1958706378936768, valid_acc: 36.8682390659026\n",
      "\n",
      "Epoch 5 train_loss: 0.9366679191589355, train_acc: 58.88955283136189, valid_loss: 1.199886441230774, valid_acc: 35.256582612933016\n",
      "\n",
      "Epoch 6 train_loss: 0.917393147945404, train_acc: 61.55254845846976, valid_loss: 1.1876857280731201, valid_acc: 38.230670394466365\n",
      "\n",
      "Epoch 7 train_loss: 0.8994804620742798, train_acc: 63.03429315520835, valid_loss: 1.2120639085769653, valid_acc: 37.69456518161623\n",
      "\n",
      "Epoch 8 train_loss: 0.8782653212547302, train_acc: 64.15419600084353, valid_loss: 1.2244808673858643, valid_acc: 36.72464523923241\n",
      "\n",
      "Epoch 9 train_loss: 0.8610520958900452, train_acc: 65.1915900099362, valid_loss: 1.2277787923812866, valid_acc: 38.36277390660427\n",
      "\n",
      "Epoch 10 train_loss: 0.8411558866500854, train_acc: 65.46546150954327, valid_loss: 1.2377398014068604, valid_acc: 37.65357216147967\n",
      "\n",
      "Epoch 11 train_loss: 0.831565260887146, train_acc: 66.52419982011867, valid_loss: 1.2482306957244873, valid_acc: 38.839605434360045\n",
      "\n",
      "Epoch 12 train_loss: 0.8019877672195435, train_acc: 67.50722670286149, valid_loss: 1.304704189300537, valid_acc: 36.336484942982736\n",
      "\n",
      "Epoch 13 train_loss: 0.799427330493927, train_acc: 68.43570035914924, valid_loss: 1.2611294984817505, valid_acc: 38.81422723076227\n",
      "\n",
      "Epoch 14 train_loss: 0.7902105450630188, train_acc: 69.4407690585033, valid_loss: 1.2743064165115356, valid_acc: 37.27950940908686\n",
      "\n",
      "Epoch 15 train_loss: 0.7691348791122437, train_acc: 70.48303158256947, valid_loss: 1.3087680339813232, valid_acc: 37.28316963056136\n",
      "\n",
      "Epoch 16 train_loss: 0.7666172981262207, train_acc: 71.06821766278321, valid_loss: 1.281744360923767, valid_acc: 39.56362237025274\n",
      "\n",
      "Epoch 17 train_loss: 0.7549874186515808, train_acc: 71.25293098279495, valid_loss: 1.3199101686477661, valid_acc: 39.236189347094275\n",
      "\n",
      "Epoch 18 train_loss: 0.7416908144950867, train_acc: 71.1708832984149, valid_loss: 1.3321988582611084, valid_acc: 39.37289340565567\n",
      "\n",
      "Epoch 19 train_loss: 0.7340009808540344, train_acc: 72.10266830731517, valid_loss: 1.2967272996902466, valid_acc: 40.01239379374364\n",
      "\n",
      "Epoch 20 train_loss: 0.725669264793396, train_acc: 72.690544858136, valid_loss: 1.3295295238494873, valid_acc: 39.045427035899465\n",
      "\n",
      "Epoch 21 train_loss: 0.7152498960494995, train_acc: 72.13806631037875, valid_loss: 1.3219177722930908, valid_acc: 39.4746682455142\n",
      "\n",
      "Epoch 22 train_loss: 0.7071565389633179, train_acc: 73.28041224900548, valid_loss: 1.3575400114059448, valid_acc: 38.34422619988772\n",
      "\n",
      "Epoch 23 train_loss: 0.7074519395828247, train_acc: 73.24228518813398, valid_loss: 1.3747963905334473, valid_acc: 40.41048001032036\n",
      "\n",
      "Epoch 24 train_loss: 0.6974932551383972, train_acc: 73.77876986665942, valid_loss: 1.3710553646087646, valid_acc: 38.75419357652949\n",
      "\n",
      "Epoch 25 train_loss: 0.6939515471458435, train_acc: 73.87472957447508, valid_loss: 1.3815728425979614, valid_acc: 39.32246881916883\n",
      "\n",
      "Epoch 26 train_loss: 0.6793421506881714, train_acc: 74.49642651950853, valid_loss: 1.3888388872146606, valid_acc: 39.937199835410006\n",
      "\n",
      "Epoch 27 train_loss: 0.6780189275741577, train_acc: 73.97064046242822, valid_loss: 1.4390960931777954, valid_acc: 38.13266921274257\n",
      "\n",
      "Epoch 28 train_loss: 0.6716378927230835, train_acc: 75.00671647556901, valid_loss: 1.408130407333374, valid_acc: 39.060658738039436\n",
      "\n",
      "Epoch 29 train_loss: 0.6610680818557739, train_acc: 75.23720269499957, valid_loss: 1.4131430387496948, valid_acc: 39.527419046129495\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# NOTE:this only tests on the original training set\n",
    "# need to figure out this train vs test vectorizer fit issue\n",
    "# see https://github.com/uclnlp/fakenewschallenge/blob/badc65fb8d06b840ab25093ea5fdd4bc3a365c30/pred.py#L53\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\", device)\n",
    "mlp = Net()\n",
    "\n",
    "mlp = mlp.to(device)\n",
    "\n",
    "# another one with reweigth\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = FocalLoss() give 30% train, 70% test, but only learned partially true, or dice_loss()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses, train_accuracies, valid_losses, valid_accuracies = train_mlp(train_loader, criterion, optimizer, mlp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "Nm38PyVr-obU",
    "outputId": "b731bfdf-40b4-4eb0-b293-de8f0ffde7c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 train_loss: 0.6589701175689697, train_acc: 76.18821608100117, valid_loss: 1.3887832164764404, valid_acc: 40.01792061922994\n",
      "\n",
      "Epoch 1 train_loss: 0.652056097984314, train_acc: 76.17252376656648, valid_loss: 1.4808026552200317, valid_acc: 39.1582900043939\n",
      "\n",
      "Epoch 2 train_loss: 0.6485286355018616, train_acc: 76.42817774045085, valid_loss: 1.445001244544983, valid_acc: 39.15339265295653\n",
      "\n",
      "Epoch 3 train_loss: 0.6389092206954956, train_acc: 76.93271101932963, valid_loss: 1.4267200231552124, valid_acc: 40.08558334253368\n",
      "\n",
      "Epoch 4 train_loss: 0.6491318345069885, train_acc: 76.08449173965242, valid_loss: 1.4487345218658447, valid_acc: 39.55267700390351\n",
      "\n",
      "Epoch 5 train_loss: 0.6401678323745728, train_acc: 76.76893002615952, valid_loss: 1.4548951387405396, valid_acc: 40.25895946153169\n",
      "\n",
      "Epoch 6 train_loss: 0.6325985789299011, train_acc: 76.46077179109322, valid_loss: 1.473334550857544, valid_acc: 39.36075646595149\n",
      "\n",
      "Epoch 7 train_loss: 0.6304131746292114, train_acc: 77.28939766465874, valid_loss: 1.5277961492538452, valid_acc: 38.5092688106284\n",
      "\n",
      "Epoch 8 train_loss: 0.63230961561203, train_acc: 76.77204192095856, valid_loss: 1.5002964735031128, valid_acc: 38.80878772655296\n",
      "\n",
      "Epoch 9 train_loss: 0.6210644245147705, train_acc: 78.3771469849086, valid_loss: 1.514966607093811, valid_acc: 38.56501177117464\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracies, valid_losses, valid_accuracies = train_mlp(train_loader, criterion, optimizer, mlp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "yziF_VlLxxQj",
    "outputId": "8cfae621-f79a-430c-89a5-99a365c70ea9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 2 1 0]\n",
      "[0 0 1 ... 2 2 1]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         false       0.49      0.42      0.45      1446\n",
      "partially true       0.42      0.41      0.42      1324\n",
      "          true       0.13      0.23      0.17       334\n",
      "\n",
      "      accuracy                           0.39      3104\n",
      "     macro avg       0.35      0.35      0.35      3104\n",
      "  weighted avg       0.42      0.39      0.41      3104\n",
      "\n",
      "0.40619385627114063\n"
     ]
    }
   ],
   "source": [
    "# val loader is the regular one, validation loader is the rebalanced one\n",
    "valid_acc_report(valid_loader, device, mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "FgaN8ZgfifOp",
    "outputId": "d5990fad-1e89-4c78-e928-6dd70a8cadd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n",
      "[0 0 1 ... 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      5954\n",
      "           1       0.76      0.78      0.77      5125\n",
      "           2       0.73      0.84      0.78      1361\n",
      "\n",
      "    accuracy                           0.77     12440\n",
      "   macro avg       0.76      0.78      0.77     12440\n",
      "weighted avg       0.77      0.77      0.76     12440\n",
      "\n",
      "0.7649047533391684\n"
     ]
    }
   ],
   "source": [
    "train_loader_for_val = torch.utils.data.DataLoader(train_dataset, batch_size=8, \n",
    "                                            drop_last=True)\n",
    "valid_acc_report(train_loader_for_val, device, mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5Jt4szU7LIr"
   },
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Wqbkf1-_xXvc",
    "outputId": "8f09d462-f7d3-4376-916a-d1ec6ba52e7f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n55zDg4Fzzjk8GDjnnAP+H31Bpb5nMFZ3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "num_epochs = 30\n",
    "plt.title('MLP Learning Curves - Loss')\n",
    "plt.plot(range(num_epochs), train_losses, color='blue', label='Training loss')\n",
    "plt.plot(range(num_epochs), valid_losses, color='red', label='Validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('MLP Learning Curves - Accuracy')\n",
    "plt.plot(range(num_epochs), train_accuracies, color='blue', label='Training accuracy')\n",
    "plt.plot(range(num_epochs), valid_accuracies, color='red', label='Validation accuracy')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CTiNSeIdSV2X",
    "outputId": "c3abdbf9-94f3-44dd-d550-c512f16d2320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'My Drive'\n"
     ]
    }
   ],
   "source": [
    "#!ls drive/My\\ Drive\n",
    "MY_HOME = 'drive/My Drive/' #metadata_articles_dataframe.pkl\n",
    "!ls drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSrl0clM1r8C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "data = pd.read_pickle(os.path.join(MY_HOME, \"nlp/preprocessed_training_dataframe.pkl\"))\n",
    "# define documents\n",
    "docs = data['X'][0:12000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3tdQdMLcFuG"
   },
   "source": [
    "# KERAS to try the word embedding method\n",
    "- [ ] separate them into proper functions\n",
    "- [ ] try to use the FC and fit_transform of SKLEARN TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN7BdkbM41H-"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "JOh6gDWEcEN9",
    "outputId": "a7865feb-52f5-4620-9c53-b3ec18f11259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "0        0\n",
      "1        2\n",
      "4        1\n",
      "5        2\n",
      "6        2\n",
      "        ..\n",
      "13211    2\n",
      "13212    0\n",
      "13213    1\n",
      "13214    1\n",
      "13215    0\n",
      "Name: label, Length: 12000, dtype: int64\n",
      "Loaded 400000 word vectors.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 50)            16058550  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 16,090,681\n",
      "Trainable params: 32,131\n",
      "Non-trainable params: 16,058,550\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7409034b00>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_pickle(os.path.join(MY_HOME, \"nlp/preprocessed_training_dataframe.pkl\"))\n",
    "# define documents\n",
    "docs = data['X'][0:12000]\n",
    "# define class labels\n",
    "labels = data['label'][0:12000]\n",
    "print(labels)\n",
    "# convert labels to onehot\n",
    "labels = one_hot(labels, 3)\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "# pad documents to a max length of 300 words\n",
    "max_length = 20\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post', truncating='post')\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open(os.path.join(MY_HOME, 'nlp/glove.6B.50d.txt'))\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 50))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m,precision_m, recall_m])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=100, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "ipOjvbfMcCyU",
    "outputId": "486230f4-a7d8-41fd-9030-48b8a3682f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "13216    1\n",
      "13217    0\n",
      "13218    1\n",
      "13219    2\n",
      "13220    0\n",
      "        ..\n",
      "17137    2\n",
      "17138    0\n",
      "17139    0\n",
      "17140    2\n",
      "17141    1\n",
      "Name: label, Length: 3555, dtype: int64\n",
      "Accuracy: 63.769340\n",
      "f1_score, precision, recall 0.36785523177199225 0.43943006579886007 0.3181434599156118\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "# define documents\n",
    "docs = data['X'][12000:15555]\n",
    "# define class labels\n",
    "labels = data['label'][12000:15555]\n",
    "print(labels)\n",
    "# convert labels to onehot\n",
    "labels = one_hot(labels, 3)\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 20\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print(\"f1_score, precision, recall\", f1_score, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "d6erWWMf4pGn",
    "outputId": "2f847310-ac23-4134-9871-a895f3e9c98b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555/3555 [==============================] - 0s 18us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.53      0.49      1638\n",
      "           1       0.43      0.45      0.44      1530\n",
      "           2       0.10      0.02      0.03       387\n",
      "\n",
      "    accuracy                           0.44      3555\n",
      "   macro avg       0.33      0.33      0.32      3555\n",
      "weighted avg       0.41      0.44      0.42      3555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict_classes(padded_docs, batch_size=64, verbose=1)\n",
    "# y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(np.argmax(labels, axis=1), y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of text_sentiment_ngrams_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
